{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFL Edge Coverage Analysis  \n",
    "Convert a fuzzing run into a CSV of analysis data  \n",
    "This automates afl-showmap and calculates Edge coverage against AFL, AFLFast, NEUZZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_date(path_to_file):\n",
    "    \"\"\"\n",
    "    Try to get the date that a file was created, falling back to when it was\n",
    "    last modified if that isn't possible.\n",
    "    See http://stackoverflow.com/a/39501288/1709587 for explanation.\n",
    "    \"\"\"\n",
    "    if platform.system() == 'Windows':\n",
    "        return os.path.getctime(path_to_file)\n",
    "    else:\n",
    "        stat = os.stat(path_to_file)\n",
    "        try:\n",
    "            return stat.st_birthtime\n",
    "        except AttributeError:\n",
    "            # We're probably on Linux. No easy way to get creation dates here,\n",
    "            # so we'll settle for when its content was last modified.\n",
    "            return datetime.datetime.fromtimestamp(stat.st_mtime)\n",
    "\n",
    "def reading_files(seed_dir):\n",
    "    rows_list = []\n",
    "    for filename in sorted(os.listdir(seed_dir)):\n",
    "        if filename not in ['.state', '.cur_input']: \n",
    "            #file_created_date = creation_date(seed_dir + filename)\n",
    "            dict1 = {\n",
    "            'filename': filename,\n",
    "            'm_timestamp': pd.to_datetime(os.path.getmtime(seed_dir + filename), unit='s')\n",
    "            }\n",
    "            rows_list.append(dict1)\n",
    "            \n",
    "    df_files = pd.DataFrame(rows_list)\n",
    "    return pd.DataFrame(rows_list)\n",
    "\n",
    "def call_for_precoverage(files_in, program_call):\n",
    "    pre_coverage = []\n",
    "\n",
    "    for file in os.listdir(files_in):\n",
    "        if file not in ['.state', '.cur_input']: \n",
    "\n",
    "            out = subprocess.check_output(['afl-showmap', '-q', '-e', '-o', '/dev/stdout'] + program_call + [files_in + file])\n",
    "            for line in out.splitlines():\n",
    "                # PY 3.7 - added deencoding for compatibility\n",
    "                edge = line.decode('utf-8').split(':')[0]\n",
    "                pre_coverage.append(edge)\n",
    "    return pre_coverage\n",
    "\n",
    "def call_program_for_coverage(df_files, pre_coverage, program_call, seed_folder, save_location):\n",
    "    tmp_list = []\n",
    "    raw_bitmap = {}\n",
    "    df_files['total_coverage'] = -1\n",
    "    df_files['current_coverage'] = -1\n",
    "    df_files['total_coverage_own_finds'] = -1\n",
    "\n",
    "    with open('./' + save_location + '.csv', 'a') as file_:\n",
    "        writer = csv.DictWriter(file_, df_files.reset_index().columns[1:], delimiter=';')\n",
    "\n",
    "        if file_.tell() == 0:\n",
    "            writer.writeheader()\n",
    "\n",
    "        for row in tqdm(df_files.itertuples(index=False)):    \n",
    "            out = subprocess.check_output(['afl-showmap', '-q', '-e', '-o', '/dev/stdout'] + program_call + [seed_folder + row[0]])\n",
    "\n",
    "            tmp_cnt = []\n",
    "            for line in out.splitlines():\n",
    "                # PY 3.7 - added deencoding for compatibility\n",
    "                edge = line.decode('utf-8').split(':')[0]\n",
    "                tmp_cnt.append(edge)\n",
    "                tmp_list.append(edge)\n",
    "\n",
    "            row_dict = {\n",
    "            'filename': row[0],\n",
    "            'm_timestamp': row[1],\n",
    "            #'running_s': row[2],\n",
    "            #'pretty_mtime': row[3],\n",
    "            'current_coverage': len(np.unique(tmp_cnt)),\n",
    "            'total_coverage': len(np.unique(tmp_list)),\n",
    "            'total_coverage_own_finds': len(np.unique(list(set(tmp_list) - set(pre_coverage))))\n",
    "            }\n",
    "            writer.writerow(row_dict)\n",
    "\n",
    "            tmp_list = list(np.unique(tmp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz_programs = {\n",
    "    'objdump'   : '/home/deif/gits/fuzztestbench/objdumppre/'\n",
    ",    'nm'       : '/home/deif/gits/fuzztestbench/nmpre/'\n",
    ",    'ffmpeg'   : '/home/deif/gits/fuzztestbench/ffmpegpre/'\n",
    ",    'harfbuzz' : '/home/deif/gits/fuzztestbench/harfbuzzpre/'\n",
    ",    'readelf'  : '/home/deif/gits/fuzztestbench/readelfpre/'\n",
    ",    'gif2png'  : '/home/deif/gits/fuzztestbench/gif2pngpre/'\n",
    ",    'mupdf'    : '/home/deif/gits/fuzztestbench/mupdfpre/'\n",
    ",    'size'     : '/home/deif/gits/fuzztestbench/sizepre/'\n",
    "}\n",
    "\n",
    "program_arguments = {\n",
    "    'objdump'   : 'objdump -D'\n",
    ",    'nm'       : 'nm-new -C'\n",
    ",    'ffmpeg'   : 'ffmpeg -i'\n",
    ",    'gif2png'  : 'gif2png'\n",
    ",    'mupdf'    : 'mutool show'\n",
    ",    'size'     : 'size'\n",
    ",    'harfbuzz' : 'hb-fuzzer' \n",
    ",    'readelf'  : 'readelf -a'\n",
    "}\n",
    "\n",
    "algorithms = ['afl', 'aflfast', 'curious', 'neuzz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/514 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 514/514 [00:00<00:00, 3039.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuzz m_time replacement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "26it [00:00, 252.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "50it [00:00, 245.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "73it [00:00, 239.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "96it [00:00, 234.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "119it [00:00, 230.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "141it [00:00, 227.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "163it [00:00, 224.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "185it [00:00, 221.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "208it [00:00, 221.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "230it [00:01, 219.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "252it [00:01, 216.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "274it [00:01, 211.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "295it [00:01, 209.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "316it [00:01, 209.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "337it [00:01, 208.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "358it [00:01, 208.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "379it [00:01, 207.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "400it [00:01, 205.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "421it [00:01, 202.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "442it [00:02, 200.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "463it [00:02, 199.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "483it [00:02, 197.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "503it [00:02, 195.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "523it [00:02, 195.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "543it [00:02, 194.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "563it [00:02, 192.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "583it [00:02, 189.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "602it [00:02, 187.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "621it [00:03, 187.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "640it [00:03, 187.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "659it [00:03, 187.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "678it [00:03, 187.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "697it [00:03, 186.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "716it [00:03, 184.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "735it [00:03, 182.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "754it [00:03, 181.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "773it [00:03, 181.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "792it [00:03, 181.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "811it [00:04, 180.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "830it [00:04, 179.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "848it [00:04, 179.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "866it [00:04, 178.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "884it [00:04, 178.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "902it [00:04, 160.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "921it [00:04, 165.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "939it [00:04, 169.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "957it [00:04, 171.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "975it [00:05, 172.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "993it [00:05, 173.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "1011it [00:05, 174.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "1029it [00:05, 172.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "1047it [00:05, 171.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "1065it [00:05, 169.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "1083it [00:05, 167.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "1100it [00:05, 165.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "1117it [00:05, 164.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "1134it [00:05, 164.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1151it [00:06, 161.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "1168it [00:06, 160.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "1185it [00:06, 156.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "1201it [00:06, 156.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "1217it [00:06, 157.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "1234it [00:06, 159.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "1251it [00:06, 160.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "1268it [00:06, 160.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "1285it [00:06, 160.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "1302it [00:07, 160.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "1319it [00:07, 160.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "1336it [00:07, 159.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "1352it [00:07, 157.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "1368it [00:07, 157.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "1384it [00:07, 157.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "1400it [00:07, 157.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "1416it [00:07, 157.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "1432it [00:07, 157.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "1449it [00:07, 158.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "1465it [00:08, 157.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "1481it [00:08, 157.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "1498it [00:08, 158.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "1514it [00:08, 157.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "1530it [00:08, 157.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "1546it [00:08, 156.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "1562it [00:08, 156.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "1578it [00:08, 156.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "1594it [00:08, 155.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "1610it [00:08, 156.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "1626it [00:09, 157.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "1643it [00:09, 158.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "1659it [00:09, 158.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "1675it [00:09, 158.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "1691it [00:09, 141.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "1707it [00:09, 145.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "1723it [00:09, 146.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "1739it [00:09, 148.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "1755it [00:09, 150.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "1771it [00:10, 151.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "1787it [00:10, 152.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "1803it [00:10, 153.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "1819it [00:10, 153.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "1835it [00:10, 152.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "1851it [00:10, 153.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "1867it [00:10, 151.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "1883it [00:10, 147.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "1899it [00:10, 149.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "1914it [00:10, 149.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "1929it [00:11, 148.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "1944it [00:11, 149.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "1960it [00:11, 150.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "1976it [00:11, 151.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "1992it [00:11, 150.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "2008it [00:11, 150.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "2024it [00:11, 150.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "2040it [00:11, 150.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "2056it [00:11, 150.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "2072it [00:12, 150.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "2088it [00:12, 151.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "2104it [00:12, 152.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "2120it [00:12, 151.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "2136it [00:12, 151.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "2167it [00:12, 170.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/514 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 514/514 [00:00<00:00, 2947.74it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuzz m_time replacement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/deif/envs/fuzz/lib/python3.7/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/deif/gits/fuzztestbench/sizepre/sizepreneuzz2/afl_in/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-aadd74d2cdbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#df_files = df_files.sort_values('m_timestamp')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# Calling for pre-coverage (what coverage does the input have?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mpre_coverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_for_precoverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minseed_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogram_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;31m#for inseed_path in inseed_paths:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#   pre_coverage += call_for_precoverage(inseed_path, program_call)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-df1b1362e456>\u001b[0m in \u001b[0;36mcall_for_precoverage\u001b[0;34m(files_in, program_call)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpre_coverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'.state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.cur_input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/deif/gits/fuzztestbench/sizepre/sizepreneuzz2/afl_in/'"
     ]
    }
   ],
   "source": [
    "program = 'nm'\n",
    "for algorithm in algorithms:\n",
    "    for i in range(1,6):\n",
    "        base_path = fuzz_programs[program]\n",
    "\n",
    "        if algorithm == 'neuzz':\n",
    "            seed_path = '/home/deif/gits/neuzz/programs/'+program + str(i)+'/seeds/'\n",
    "        else:\n",
    "            seed_path = base_path + program + 'pre' + algorithm + str(i) + '/afl_out/queue/'\n",
    "\n",
    "        save_location = 'edgecoverage/' + program + 'pre/' + program + 'pre' + algorithm + str(i)\n",
    "\n",
    "        inseed_paths = [base_path + program + 'pre' + algorithm + \"1\" + '/afl_in/']\n",
    "\n",
    "        if len(os.listdir(seed_path)) > 1:\n",
    "            if ' ' in str(program_arguments[program]):\n",
    "                program_call = str(fuzz_programs[program]+program_arguments[program]).split(' ')\n",
    "            else:\n",
    "                program_call = [fuzz_programs[program]+program_arguments[program]]\n",
    "\n",
    "            df_files = reading_files(seed_path)\n",
    "            if False: #algorithm == 'neuzz':\n",
    "                #replace mtime of neuzz starter with real mtime\n",
    "                print(\"neuzz m_time replacement\")\n",
    "                df_files = df_files.set_index(\"filename\")\n",
    "                for filename in tqdm(sorted(os.listdir(inseed_paths[1]))):\n",
    "                    if filename not in ['.state', '.cur_input']: \n",
    "                        df_files.loc[filename, 'm_timestamp'] = pd.to_datetime(os.path.getmtime(inseed_paths[1] + filename), unit='s')\n",
    "                df_files = df_files.reset_index()\n",
    "            # Running Time\n",
    "            #creation_date = df_files.iloc[1]['m_timestamp']\n",
    "            #df_files = df_files.loc[df_files['m_timestamp']<(creation_date + pd.Timedelta(days=1))]\n",
    "\n",
    "            #df_files['running_s'] = df_files['m_timestamp'] - creation_date\n",
    "            #df_files = df_files.sort_values('m_timestamp')\n",
    "            #df_files['running_s'] = df_files['running_s'].apply(lambda x: x if x.total_seconds()>0.0 else 0.0) \n",
    "            df_files['m_timestamp'].iloc[0] = df_files['m_timestamp'].iloc[1]\n",
    "            #df_files = df_files.sort_values('m_timestamp')\n",
    "            # Calling for pre-coverage (what coverage does the input have?)\n",
    "            pre_coverage = call_for_precoverage(inseed_paths[0], program_call)\n",
    "            #for inseed_path in inseed_paths:\n",
    "            #   pre_coverage += call_for_precoverage(inseed_path, program_call)\n",
    "            #pre_coverage = np.unique(pre_coverage)\n",
    "            call_program_for_coverage(df_files, pre_coverage, program_call, seed_path, save_location)\n",
    " #   except:\n",
    " #       continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEUZZ special treatment  \n",
    "because the folder structure and seed handling make no sense at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = 'harfbuzz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./edgecoverage/' + program + 'pre/' + program + 'preneuzz1.csv', sep=\";\")\n",
    "df['m_timestamp'] = pd.to_datetime(df['m_timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### usual treatment - adjust initial seed timestamp to beginning of fuzzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['m_timestamp'].iloc[0] = df['m_timestamp'].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### special treatment - adjust neuzz's seeds to stop of AFL's seed corpus stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find timedelta\n",
    "afl_neuzz_delta = df.loc[~df['filename'].str.startswith('id:00')].iloc[0]['m_timestamp'] - df.loc[df['filename'].str.startswith('id:00')].iloc[-1]['m_timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deif/envs/fuzz/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.loc[~df['filename'].str.startswith('id:00')]['m_timestamp'] = df.loc[~df['filename'].str.startswith('id:00')]['m_timestamp'] - afl_neuzz_delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phew that was ... strange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['running_s'] = round((df['m_timestamp'] - df['m_timestamp'].iloc[0]).dt.total_seconds(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./edgecoverage/' + program + 'pre/' + program + 'preneuzz1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/david/Documents/gits/MA-Scripts/SeedFolderToCoverageData/objdumppreafl1/'\n",
    "seed_dir = project_dir + 'afl_out/queue/'\n",
    "exec_dir = project_dir + 'objdump'\n",
    "in_dir = project_dir + 'afl_in/'\n",
    "args = ['-D']\n",
    "\n",
    "initial_seed = os.listdir(seed_dir)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = df_files.sort_values(by=['m_timestamp'])\n",
    "#df_files['modification_date'] = df_files['modification_date'].dt.round('1s')\n",
    "#df_files['modification_date'] = df_files['modification_date'].apply(lambda x: x.time())\n",
    "creation_date = df_files.iloc[1]['m_timestamp']\n",
    "df_files['running_s'] = df_files['m_timestamp'] - creation_date\n",
    "df_files['running_s'] = df_files['running_s'].apply(lambda x: x if x>0 else 0.0) \n",
    "df_files['pretty_mtime'] = df_files['m_timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "\n",
    "df_files = df_files.set_index('filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_files.reset_index().columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
